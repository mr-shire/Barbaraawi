name: Build Podcast and Upload to Internet Archive (safe filenames + quoting)

on:
  workflow_dispatch:
  push:
    branches:
      - main
      - master

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install ffmpeg, IA CLI, and latest yt-dlp nightly
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg jq curl
          python -m pip install --upgrade pip
          pip install internetarchive
          pip install --upgrade --force-reinstall "yt-dlp @ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"

      - name: Create cookies.txt if provided
        env:
          YT_COOKIES_TXT: ${{ secrets.YT_COOKIES_TXT }}
        run: |
          if [ -n "$YT_COOKIES_TXT" ]; then
            printf '%s' "$YT_COOKIES_TXT" > cookies.txt
            chmod 600 cookies.txt
            echo "✓ cookies.txt created"
          else
            echo "No cookies provided — proceeding without"
          fi

      - name: Download, sanitize, and upload each MP3
        env:
          YOUTUBE_PLAYLIST_URL: ${{ secrets.YOUTUBE_PLAYLIST_URL }}
          IA_BUCKET_IDENTIFIER: ${{ secrets.IA_BUCKET_IDENTIFIER }}
          IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
          IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
          IA_COLLECTION: ${{ secrets.IA_COLLECTION }}
          IA_LICENSE_URL: ${{ secrets.IA_LICENSE_URL }}
        shell: bash
        run: |
          set -o pipefail
          mkdir -p downloads

          sanitize_stem () {
            tr '\n' ' ' \
            | iconv -f utf-8 -t ascii//TRANSLIT \
            | tr ' ' '_' \
            | sed 's/[^A-Za-z0-9._-]//g' \
            | sed 's/[_-]\{2,\}/_/g' \
            | sed 's/^[_-]*//;s/[_-]*$//' \
            | tr '[:upper:]' '[:lower:]' \
            | awk '{ s=$0; if (length(s)>80) s=substr(s,1,80); print s }'
          }

          if [ -f cookies.txt ]; then
            COOKIES_FLAG=(--cookies cookies.txt)
          else
            COOKIES_FLAG=()
          fi

          mapfile -t videos < <(yt-dlp --flat-playlist --print "%(id)s\t%(title)s" "$YOUTUBE_PLAYLIST_URL")

          for entry in "${videos[@]}"; do
            vid="${entry%%$'\t'*}"
            orig_title="${entry#*$'\t'}"
            echo "=== Processing video $vid ==="

            yt-dlp \
              --ignore-no-formats-error \
              --no-abort-on-error \
              --retries infinite \
              --fragment-retries infinite \
              --continue \
              --extract-audio \
              --audio-format mp3 \
              --audio-quality 0 \
              --embed-thumbnail \
              --add-metadata \
              -o "downloads/%(title)s [%(id)s].%(ext)s" \
              "${COOKIES_FLAG[@]}" \
              "https://www.youtube.com/watch?v=$vid" || {
                echo "::error::Download failed for $vid"
                echo "-----------------------------------"
                continue
              }

            shopt -s nullglob
            matches=( downloads/*\ [${vid}].mp3 )
            shopt -u nullglob
            if [ ${#matches[@]} -eq 0 ]; then
              echo "::error::❌ No MP3 found for $vid after download."
              echo "-----------------------------------"
              continue
            fi
            src_mp3="${matches[0]}"
            echo "✅ MP3 created: $src_mp3"

            safe_stem=$(printf '%s' "$orig_title" | sanitize_stem)
            [ -z "$safe_stem" ] && safe_stem="episode"
            final_name="${safe_stem}__${vid}.mp3"
            final_name=$(printf '%s' "$final_name" | sed 's/[^A-Za-z0-9._-]//g' | tr '[:upper:]' '[:lower:]')
            final_path="downloads/$final_name"

            if [ "$src_mp3" != "$final_path" ]; then
              mv -f -- "$src_mp3" "$final_path"
              echo "Renamed to IA-safe: $final_path"
            fi

            echo -e "${final_name}\t${orig_title}" >> downloads/title_map.txt

            remote_url="https://archive.org/download/${IA_BUCKET_IDENTIFIER}/${final_name}"
            if curl -sfI "$remote_url" >/dev/null; then
              echo "ℹ️ Already on IA: ${final_name} — skipping upload."
              echo "-----------------------------------"
              continue
            fi

            max_attempts=5
            delay=5
            attempt=1
            upload_ok=0
            while [ $attempt -le $max_attempts ]; do
              echo "Uploading to IA (attempt $attempt/$max_attempts)..."
              IA_ACCESS_KEY="$IA_ACCESS_KEY" IA_SECRET_KEY="$IA_SECRET_KEY" \
              ia upload "$IA_BUCKET_IDENTIFIER" "$final_path" \
                --metadata="collection:${IA_COLLECTION}" \
                --metadata="licenseurl:${IA_LICENSE_URL}" \
                --metadata="mediatype:audio" \
                --metadata="title:${orig_title}" \
                --metadata="originalurl:https://www.youtube.com/watch?v=${vid}"
              rc=$?
              if [ $rc -eq 0 ] && curl -sfI "$remote_url" >/dev/null; then
                echo "✅ Upload confirmed on IA: $remote_url"
                upload_ok=1
                break
              else
                echo "::warning::Upload attempt $attempt failed or not visible yet."
                sleep $delay
              fi
              attempt=$((attempt + 1))
              delay=$((delay * 2))
              [ $delay -gt 60 ] && delay=60
            done

            [ $upload_ok -ne 1 ] && echo "::error::Upload failed after retries for ${final_name}"
            sleep 2
            echo "-----------------------------------"
          done

      - name: Fail if no MP3s found locally
        shell: bash
        run: |
          shopt -s nullglob
          files=(downloads/*.mp3)
          if [ ${#files[@]} -eq 0 ]; then
            echo "::error::No MP3 files found. Check the per-file logs above."
            exit 1
          fi

      - name: Build Apple Podcasts–ready RSS feed
        env:
          PODCAST_TITLE: ${{ secrets.PODCAST_TITLE }}
          PODCAST_AUTHOR: ${{ secrets.PODCAST_AUTHOR }}
          PODCAST_DESCRIPTION: ${{ secrets.PODCAST_DESCRIPTION }}
          PODCAST_OWNER_EMAIL: ${{ secrets.PODCAST_OWNER_EMAIL }}
          PODCAST_CATEGORY: ${{ secrets.PODCAST_CATEGORY }}
          IA_BUCKET_IDENTIFIER: ${{ secrets.IA_BUCKET_IDENTIFIER }}
        run: python scripts/build_feed.py

      - name: Prepare Pages artifact
        run: |
          mkdir -p public
          cp -- out/podcast.xml public/

      - name: Upload artifact for GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    steps:
      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
