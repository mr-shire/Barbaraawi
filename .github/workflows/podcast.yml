name: Build Podcast and Upload to Internet Archive (final safe filenames)

on:
  workflow_dispatch:
  push:
    branches:
      - main
      - master

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install ffmpeg, IA CLI, and latest yt-dlp nightly
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          python -m pip install --upgrade pip
          pip install internetarchive
          pip install --upgrade --force-reinstall "yt-dlp @ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"

      - name: Create cookies.txt if provided
        env:
          YT_COOKIES_TXT: ${{ secrets.YT_COOKIES_TXT }}
        run: |
          if [ -n "$YT_COOKIES_TXT" ]; then
            printf '%s' "$YT_COOKIES_TXT" > cookies.txt
            chmod 600 cookies.txt
            echo "✓ cookies.txt created"
          else
            echo "No cookies provided — proceeding without"
          fi

      - name: Download, sanitise, and upload each MP3
        env:
          YOUTUBE_PLAYLIST_URL: ${{ secrets.YOUTUBE_PLAYLIST_URL }}
          IA_BUCKET_IDENTIFIER: ${{ secrets.IA_BUCKET_IDENTIFIER }}
          IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
          IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
          IA_COLLECTION: ${{ secrets.IA_COLLECTION }}
          IA_LICENSE_URL: ${{ secrets.IA_LICENSE_URL }}
        shell: bash
        run: |
          set -o pipefail
          mkdir -p downloads

          if [ -f cookies.txt ]; then
            COOKIES_FLAG=(--cookies cookies.txt)
          else
            COOKIES_FLAG=()
          fi

          # Get video IDs and titles
          mapfile -t videos < <(yt-dlp --flat-playlist --print "%(id)s\t%(title)s" "$YOUTUBE_PLAYLIST_URL")

          for entry in "${videos[@]}"; do
            vid="${entry%%$'\t'*}"
            orig_title="${entry#*$'\t'}"
            echo "=== Processing video $vid ==="

            # Download single video
            yt-dlp \
              --ignore-errors \
              --ignore-no-formats-error \
              --no-abort-on-error \
              --retries infinite \
              --fragment-retries infinite \
              --continue \
              --extract-audio \
              --audio-format mp3 \
              --audio-quality 0 \
              --embed-thumbnail \
              --add-metadata \
              -o "downloads/%(title)s [%(id)s].%(ext)s" \
              "${COOKIES_FLAG[@]}" \
              "https://www.youtube.com/watch?v=$vid" || {
                echo "::error::Download failed for $vid"
                echo "-----------------------------------"
                continue
              }

            # Find MP3 for this video ID
            file_glob="downloads/* [${vid}].mp3"
            shopt -s nullglob
            matches=( $file_glob )
            shopt -u nullglob

            if [ ${#matches[@]} -eq 0 ]; then
              echo "::error::❌ No MP3 found for $vid after download."
              echo "-----------------------------------"
              continue
            fi

            mp3="${matches[0]}"
            echo "✅ MP3 created: $mp3"

            # Create strict IA-safe ASCII filename
            safe_name=$(basename "$mp3" \
              | iconv -f utf-8 -t ascii//TRANSLIT \
              | tr ' ' '_' \
              | sed 's/[^A-Za-z0-9._-]//g')
            safe_path="downloads/$safe_name"
            if [ "$mp3" != "$safe_path" ]; then
              mv "$mp3" "$safe_path"
              echo "Renamed for IA: $safe_path"
            fi

            # Save mapping for RSS builder
            echo -e "${safe_name}\t${orig_title}" >> downloads/title_map.txt

            # Skip upload if already on IA
            remote_url="https://archive.org/download/${IA_BUCKET_IDENTIFIER}/$(basename "$safe_path")"
            if curl -sfI "$remote_url" >/dev/null; then
              echo "ℹ️ Already on IA: $(basename "$safe_path") — skipping upload."
              echo "-----------------------------------"
              continue
            fi

            echo "Uploading to Internet Archive..."
            IA_ACCESS_KEY="$IA_ACCESS_KEY" IA_SECRET_KEY="$IA_SECRET_KEY" \
            ia upload "$IA_BUCKET_IDENTIFIER" "$safe_path" \
              --metadata="collection:$IA_COLLECTION" \
              --metadata="licenseurl:$IA_LICENSE_URL" \
              --metadata="mediatype:audio" \
              --metadata="title:$orig_title" || {
                echo "::error::Upload failed for $safe_path"
                echo "-----------------------------------"
                continue
              }

            # Confirm upload
            if curl -sfI "$remote_url" >/dev/null; then
              echo "✅ Upload confirmed on IA: $remote_url"
            else
              echo "::warning::Upload may be processing. Not visible yet: $remote_url"
            fi
            echo "-----------------------------------"
          done

      - name: Fail if no MP3s found locally
        shell: bash
        run: |
          shopt -s nullglob
          files=(downloads/*.mp3)
          if [ ${#files[@]} -eq 0 ]; then
            echo "::error::No MP3 files found. Check the per-file logs above."
            exit 1
          fi

      - name: Build Apple Podcasts–ready RSS feed
        env:
          PODCAST_TITLE: ${{ secrets.PODCAST_TITLE }}
          PODCAST_AUTHOR: ${{ secrets.PODCAST_AUTHOR }}
          PODCAST_DESCRIPTION: ${{ secrets.PODCAST_DESCRIPTION }}
          PODCAST_OWNER_EMAIL: ${{ secrets.PODCAST_OWNER_EMAIL }}
          PODCAST_CATEGORY: ${{ secrets.PODCAST_CATEGORY }}
          IA_BUCKET_IDENTIFIER: ${{ secrets.IA_BUCKET_IDENTIFIER }}
        run: python scripts/build_feed.py

      - name: Prepare Pages artifact
        run: |
          mkdir -p public
          cp out/podcast.xml public/

      - name: Upload artifact for GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    steps:
      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
