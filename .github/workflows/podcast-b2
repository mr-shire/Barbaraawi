name: One-time YouTube Playlist to Podcast (Backblaze B2 Private, Verified Uploads)

on:
  workflow_dispatch: # manual trigger only

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install ffmpeg, B2 CLI, and latest yt-dlp nightly
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y ffmpeg jq curl
          python -m pip install --upgrade pip
          pip install b2
          # Nightly/master build to keep up with YT changes
          pip install --upgrade --force-reinstall "yt-dlp @ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz"

      - name: Create cookies.txt if provided
        env:
          YT_COOKIES_TXT: ${{ secrets.YT_COOKIES_TXT }}
        run: |
          if [ -n "$YT_COOKIES_TXT" ]; then
            printf '%s' "$YT_COOKIES_TXT" > cookies.txt
            chmod 600 cookies.txt
            echo "✓ cookies.txt created"
          else
            echo "No cookies provided — proceeding without"
          fi

      - name: Debug playlist fetch
        env:
          YOUTUBE_PLAYLIST_URL: ${{ secrets.YOUTUBE_PLAYLIST_URL }}
        run: |
          set -euo pipefail
          echo "yt-dlp version:"
          yt-dlp --version
          echo "Attempting to list playlist entries..."
          if [ -f cookies.txt ]; then
            yt-dlp --flat-playlist --print "%(id)s\t%(title)s" --cookies cookies.txt "$YOUTUBE_PLAYLIST_URL" | tee playlist_preview.txt
          else
            yt-dlp --flat-playlist --print "%(id)s\t%(title)s" "$YOUTUBE_PLAYLIST_URL" | tee playlist_preview.txt
          fi
          count=$(wc -l < playlist_preview.txt | tr -d ' ')
          echo "Found $count entries."
          if [ "$count" -eq 0 ]; then
            echo "::error::No videos found. Check playlist URL, privacy/region settings, or add YT_COOKIES_TXT."
            exit 1
          fi

      - name: Download, sanitize, verify, and upload each MP3 (Backblaze B2 private)
        env:
          YOUTUBE_PLAYLIST_URL: ${{ secrets.YOUTUBE_PLAYLIST_URL }}
          B2_BUCKET_NAME: ${{ secrets.B2_BUCKET_NAME }}
          B2_KEY_ID: ${{ secrets.B2_KEY_ID }}
          B2_APPLICATION_KEY: ${{ secrets.B2_APPLICATION_KEY }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p downloads out
          : > downloads/verified.txt
          : > downloads/url_map.txt
          : > downloads/title_map.txt

          sanitize_stem () {
            tr '\n' ' ' \
            | iconv -f utf-8 -t ascii//TRANSLIT \
            | tr ' ' '_' \
            | sed 's/[^A-Za-z0-9._-]//g' \
            | sed 's/[_-]\{2,\}/_/g' \
            | sed 's/^[_-]*//;s/[_-]*$//' \
            | tr '[:upper:]' '[:lower:]' \
            | awk '{ s=$0; if (length(s)>80) s=substr(s,1,80); print s }'
          }

          if [ -f cookies.txt ]; then
            COOKIES_FLAG=(--cookies cookies.txt)
          else
            COOKIES_FLAG=()
          fi

          # Use the exact list captured by the debug step
          mapfile -t videos < playlist_preview.txt

          # Authorize Backblaze (private bucket)
          auth_json=$(b2 authorize-account "$B2_KEY_ID" "$B2_APPLICATION_KEY")
          download_url=$(echo "$auth_json" | jq -r '.downloadUrl')

          for entry in "${videos[@]}"; do
            vid="${entry%%$'\t'*}"
            orig_title="${entry#*$'\t'}"
            [ -z "$vid" ] && continue

            echo "=== Processing video $vid ==="

            # Extract audio to MP3 with resilient flags
            yt-dlp \
              --extractor-args "youtube:player_client=web" \
              --ignore-no-formats-error \
              --no-abort-on-error \
              --retries 20 \
              --fragment-retries 20 \
              --sleep-requests 2 \
              --sleep-interval 2 \
              --max-sleep-interval 5 \
              --continue \
              --extract-audio \
              --audio-format mp3 \
              --audio-quality 0 \
              --embed-thumbnail \
              --add-metadata \
              -o "downloads/%(title)s [%(id)s].%(ext)s" \
              "${COOKIES_FLAG[@]}" \
              "https://www.youtube.com/watch?v=$vid" || {
                echo "::error::Download failed for $vid"
                echo "-----------------------------------"
                continue
              }

            shopt -s nullglob
            matches=( downloads/*\ [${vid}].mp3 )
            shopt -u nullglob
            if [ ${#matches[@]} -eq 0 ]; then
              echo "::error::❌ No MP3 found for $vid after download."
              echo "-----------------------------------"
              continue
            fi
            src_mp3="${matches[0]}"

            # Verify extraction: size and duration
            size_bytes=$(stat -c%s "$src_mp3" 2>/dev/null || stat -f%z "$src_mp3")
            if [ -z "$size_bytes" ] || [ "$size_bytes" -lt 50000 ]; then
              echo "::error::❌ MP3 too small or empty for $vid."
              rm -f -- "$src_mp3"
              echo "-----------------------------------"
              continue
            fi
            duration_sec=$(ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 "$src_mp3" || echo "0")
            duration_int=${duration_sec%.*}
            if [ -z "$duration_int" ] || [ "$duration_int" -lt 5 ]; then
              echo "::error::❌ MP3 duration < 5s for $vid (got ${duration_sec}s)."
              rm -f -- "$src_mp3"
              echo "-----------------------------------"
              continue
            fi
            echo "✅ MP3 verified (${size_bytes} bytes, ~${duration_int}s): $src_mp3"

            # Sanitize final filename
            safe_stem=$(printf '%s' "$orig_title" | sanitize_stem)
            [ -z "$safe_stem" ] && safe_stem="episode"
            final_name="${safe_stem}__${vid}.mp3"
            final_name=$(printf '%s' "$final_name" | sed 's/[^A-Za-z0-9._-]//g' | tr '[:upper:]' '[:lower:]')
            final_path="downloads/$final_name"
            if [ "$src_mp3" != "$final_path" ]; then
              mv -f -- "$src_mp3" "$final_path"
            fi

            printf '%s\t%s\n' "$final_name" "$orig_title" >> downloads/title_map.txt

            # Upload with retries (exponential backoff)
            max_attempts=5
            delay=5
            attempt=1
            upload_ok=0
            while [ $attempt -le $max_attempts ]; do
              echo "Uploading to B2 (attempt $attempt/$max_attempts): $final_name"
              if b2 upload-file --noProgress "$B2_BUCKET_NAME" "$final_path" "$final_name"; then
                # Verify presence via list-file-names
                verify_json=$(b2 list-file-names "$B2_BUCKET_NAME" "$final_name" 1 || true)
                present=$(echo "$verify_json" | jq -r --arg n "$final_name" '.files[]?.fileName == $n' | grep -c true || true)
                if [ "$present" -eq 1 ]; then
                  upload_ok=1
                  break
                fi
              fi
              echo "::warning::Upload not verified yet, retrying after ${delay}s..."
              sleep $delay
              attempt=$((attempt + 1))
              delay=$((delay * 2)); [ $delay -gt 60 ] && delay=60
            done

            if [ "$upload_ok" -ne 1 ]; then
              echo "::error::Upload failed after retries for $final_name"
              echo "-----------------------------------"
              continue
            fi

            # Generate signed URL valid for 7 days (604800 seconds) and verify it works
            auth_token=$(b2 get-download-authorisation "$B2_BUCKET_NAME" "$final_name" 604800 | jq -r '.authorizationToken')
            signed_url="${download_url}/file/${B2_BUCKET_NAME}/${final_name}?Authorization=${auth_token}"

            if ! curl -sfI --retry 5 --retry-delay 2 "$signed_url" >/dev/null; then
              echo "::error::Signed URL not reachable for $final_name"
              echo "-----------------------------------"
              continue
            fi

            # Mark verified and record for RSS
            echo -e "${final_name}\t${orig_title}" >> downloads/verified.txt
            echo -e "${final_name}\t${orig_title}\t${signed_url}" >> downloads/url_map.txt
            echo "✅ Verified on B2 and signed URL is live."
            echo "-----------------------------------"
          done

      - name: Fail if no verified uploads
        shell: bash
        run: |
          if [ ! -s downloads/verified.txt ]; then
            echo "::error::No verified uploads found. Aborting feed build."
            echo "Troubleshooting:"
            echo "- Ensure YOUTUBE_PLAYLIST_URL is a playlist (not a channel/videos page or a single video)."
            echo "- If playlist or videos are restricted (private, unlisted, age/region), set YT_COOKIES_TXT."
            echo "- Re-run. The previous step logs show exact failures per video."
            exit 1
          fi

      - name: Build Apple Podcasts–ready RSS feed (verified only, signed URLs)
        env:
          PODCAST_TITLE: ${{ secrets.PODCAST_TITLE }}
          PODCAST_AUTHOR: ${{ secrets.PODCAST_AUTHOR }}
          PODCAST_DESCRIPTION: ${{ secrets.PODCAST_DESCRIPTION }}
          PODCAST_OWNER_EMAIL: ${{ secrets.PODCAST_OWNER_EMAIL }}
          PODCAST_CATEGORY: ${{ secrets.PODCAST_CATEGORY }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p out

          esc () { python -c "import html,sys;print(html.escape(sys.stdin.read(), quote=True))"; }

          items=""
          while IFS=$'\t' read -r file title url; do
            [ -z "$file" ] && continue
            length=$(stat -c%s "downloads/$file" 2>/dev/null || stat -f%z "downloads/$file")
            pubdate="$(date -R)"
            title_xml=$(printf '%s' "$title" | esc)
            items="${items}
              <item>
                <title>${title_xml}</title>
                <enclosure url=\"${url}\" length=\"${length}\" type=\"audio/mpeg\" />
                <guid isPermaLink=\"false\">${file}</guid>
                <pubDate>${pubdate}</pubDate>
              </item>"
          done < downloads/url_map.txt

          podcast_title="${PODCAST_TITLE:-My Podcast}"
          podcast_author="${PODCAST_AUTHOR:-Creator}"
          podcast_desc="${PODCAST_DESCRIPTION:-Automated feed from YouTube}"
          podcast_email="${PODCAST_OWNER_EMAIL:-owner@example.com}"
          podcast_category="${PODCAST_CATEGORY:-Society & Culture}"

          cat > out/podcast.xml <<EOF
          <?xml version="1.0" encoding="UTF-8"?>
          <rss version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd">
            <channel>
              <title>$(printf '%s' "$podcast_title" | esc)</title>
              <link>https://github.com/${{ github.repository }}</link>
              <language>en</language>
              <itunes:author>$(printf '%s' "$podcast_author" | esc)</itunes:author>
              <itunes:owner>
                <itunes:name>$(printf '%s' "$podcast_author" | esc)</itunes:name>
                <itunes:email>$(printf '%s' "$podcast_email" | esc)</itunes:email>
              </itunes:owner>
              <description>$(printf '%s' "$podcast_desc" | esc)</description>
              <itunes:category text="$(printf '%s' "$podcast_category" | esc)"/>
              ${items}
            </channel>
          </rss>
          EOF

      - name: Prepare Pages artifact
        run: |
          mkdir -p public
          cp -- out/podcast.xml public/index.xml
          cat > public/index.html <<HTML
          <!doctype html><meta charset="utf-8">
          <title>Podcast RSS</title>
          <p>Your RSS feed is at <a href="index.xml">index.xml</a></p>
          HTML

      - name: Upload artifact for GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    steps:
      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
